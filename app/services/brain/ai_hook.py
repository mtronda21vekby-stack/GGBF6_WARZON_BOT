from __future__ import annotations

from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional
import os
import random
import time

import httpx
import certifi
from openai import OpenAI


def _difficulty_style(diff: str) -> str:
    d = (diff or "Normal").lower()
    if "demon" in d:
        return "DEMON"
    if "pro" in d:
        return "PRO"
    return "NORMAL"


@dataclass
class AIHook:
    api_key: str
    model: str = "gpt-4.1-mini"
    _cached_client: Optional[OpenAI] = field(default=None, init=False, repr=False)

    def _build_http_client(self) -> httpx.Client:
        # Render/free instances can be shaky -> give it breathing room
        timeout = httpx.Timeout(connect=20.0, read=90.0, write=45.0, pool=90.0)
        limits = httpx.Limits(max_keepalive_connections=10, max_connections=30, keepalive_expiry=60.0)

        # trust_env=True is IMPORTANT on some platforms (proxies / CA / env)
        # http2=False tends to be more stable on some free hosts
        return httpx.Client(
            timeout=timeout,
            limits=limits,
            verify=certifi.where(),
            trust_env=True,
            http2=False,
            headers={
                "User-Agent": "ggbf6-warzon-bot/1.0 (Render)",
            },
        )

    def _client(self) -> OpenAI:
        # Cache the client so we reuse connections instead of recreating every request
        if self._cached_client is not None:
            return self._cached_client

        base_url = (os.getenv("OPENAI_BASE_URL", "") or "").strip()
        http_client = self._build_http_client()

        # OpenAI SDK 1.x: pass custom http_client
        if base_url:
            self._cached_client = OpenAI(
                api_key=self.api_key,
                base_url=base_url,
                http_client=http_client,
            )
        else:
            self._cached_client = OpenAI(
                api_key=self.api_key,
                http_client=http_client,
            )

        return self._cached_client

    def generate(self, *, profile: Dict[str, Any], history: List[dict], user_text: str) -> str:
        client = self._client()

        game = profile.get("game", "Warzone")
        platform = profile.get("platform", "PC")
        input_ = profile.get("input", "Controller")
        diff = profile.get("difficulty", "Normal")
        bf6_class = profile.get("bf6_class", "Assault")
        style = _difficulty_style(diff)

        system = f"""
–¢—ã ‚Äî ultra-premium FPS Coach. –û—Ç–≤–µ—á–∞–π –∫–∞–∫ –∂–∏–≤–æ–π —Å–∏–ª—å–Ω—ã–π —Ç–∏–º–º–µ–π—Ç: –∫–æ—Ä–æ—Ç–∫–æ, –ø–æ –¥–µ–ª—É, –Ω–æ —É–º–Ω–æ.
–°—Ç–∏–ª—å: {style}

–ü—Ä–∞–≤–∏–ª–∞:
- –ù–µ –æ—Ç–≤–µ—á–∞–π —à–∞–±–ª–æ–Ω–æ–º. –í–µ–¥–∏ –¥–∏–∞–ª–æ–≥. –ù–ï –ø–æ–≤—Ç–æ—Ä—è–π –æ–¥–Ω—É –∏ —Ç—É –∂–µ —Ñ—Ä–∞–∑—É.
- –ï—Å–ª–∏ –≤–≤–æ–¥–Ω—ã—Ö –º–∞–ª–æ ‚Äî –∑–∞–¥–∞–π –º–∞–∫—Å–∏–º—É–º 1‚Äì2 —É—Ç–æ—á–Ω–µ–Ω–∏—è, –∏–Ω–∞—á–µ —Å—Ä–∞–∑—É –¥–∞–≤–∞–π –ø–ª–∞–Ω.
- –§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
  1) –î–∏–∞–≥–Ω–æ–∑
  2) –°–ï–ô–ß–ê–° (—á—Ç–æ –¥–µ–ª–∞—Ç—å –ø—Ä—è–º–æ –≤ –±–æ—é)
  3) –î–ê–õ–¨–®–ï (—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞/–Ω–∞—Å—Ç—Ä–æ–π–∫–∏/–ø—Ä–∏–≤—ã—á–∫–∏)

–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–≥—Ä–æ–∫–∞:
- game={game}
- platform={platform}
- input={input_}
- bf6_class={bf6_class}
- difficulty={diff}

–í–∞–∂–Ω–æ:
- –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø–∏—à–µ—Ç ‚Äú–ü—Ä–∏–≤–µ—Ç‚Äù –∏–ª–∏ –∫–æ—Ä–æ—Ç–∫–æ ‚Äî –Ω–µ –∑–∞–ª–∏–ø–∞–π. –î–∞–π –±—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç –∏ 1 —É—Ç–æ—á–Ω–µ–Ω–∏–µ.
- –£—á–∏—Ç—ã–≤–∞–π, —á—Ç–æ –∫–∞–∂–¥—ã–π —Ä–µ–∂–∏–º = –æ—Ç–¥–µ–ª—å–Ω—ã–π –º–∏—Ä (Warzone / BO7 / BF6).
""".strip()

        msgs: List[Dict[str, str]] = [{"role": "system", "content": system}]

        # keep last N messages
        for m in (history or [])[-20:]:
            role = (m.get("role") or "").strip()
            content = m.get("content")
            if role in ("user", "assistant") and content:
                msgs.append({"role": role, "content": str(content)})

        msgs.append({"role": "user", "content": user_text})

        # More resilient retry with jitter
        last_err: Exception | None = None

        # total tries = 4 (1 + 3 retries)
        for attempt in range(1, 5):
            try:
                resp = client.chat.completions.create(
                    model=self.model,
                    messages=msgs,
                    temperature=0.65 if style == "NORMAL" else 0.75,
                )
                out = (resp.choices[0].message.content or "").strip()
                if out:
                    return out
                return "üß† –ò–ò: –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç. –ù–∞–ø–∏—à–∏ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π: –∏–≥—Ä–∞ | input | —á—Ç–æ –±–æ–ª–∏—Ç ‚Äî –¥–∞–º –ø–ª–∞–Ω."
            except Exception as e:
                last_err = e

                # If client/connection got poisoned, drop cached client once
                # so next attempt recreates a fresh http connection pool.
                if attempt == 2:
                    self._cached_client = None

                # Backoff with jitter
                base = 0.9 * attempt
                sleep_s = base + random.uniform(0.0, 0.35)
                time.sleep(sleep_s)

        return (
            "üß† –ò–ò: ERROR\n"
            f"{type(last_err).__name__}: {last_err}\n\n"
            "–ü—Ä–æ–≤–µ—Ä—å Render ‚Üí Environment:\n"
            "‚Ä¢ OPENAI_API_KEY = —Ç–≤–æ–π –∫–ª—é—á\n"
            "‚Ä¢ AI_ENABLED=1\n"
            "‚Ä¢ OPENAI_MODEL=gpt-4.1-mini (–∏–ª–∏ –¥—Ä—É–≥–æ–π –¥–æ—Å—Ç—É–ø–Ω—ã–π)\n"
            "‚Ä¢ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) OPENAI_BASE_URL (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—à—å –ø—Ä–æ–∫—Å–∏)\n\n"
            "–ï—Å–ª–∏ —ç—Ç–æ free Render ‚Äî —Å–µ—Ç—å –∏–Ω–æ–≥–¥–∞ —Ä–≤—ë—Ç—Å—è. –¢—É—Ç —É–∂–µ:\n"
            "‚Ä¢ –∫—ç—à –∫–ª–∏–µ–Ω—Ç–∞ (reuse —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π)\n"
            "‚Ä¢ trust_env=True\n"
            "‚Ä¢ —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–µ —Ç–∞–π–º–∞—É—Ç—ã\n"
            "‚Ä¢ —Ä–µ—Ç—Ä–∞–∏ —Å jitter\n"
        )
